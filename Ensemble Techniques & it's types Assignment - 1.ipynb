{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is an ensemble technique in machine learning?# Q1. What is an ensemble technique in machine learning?\n",
    "# A1: \n",
    "# An ensemble technique in machine learning combines the predictions from multiple models to improve \n",
    "# the overall performance. Examples include bagging, boosting, and stacking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. Why are ensemble techniques used in machine learning?\n",
    "# A2: \n",
    "# Ensemble techniques are used to:\n",
    "# - Improve model accuracy and robustness.\n",
    "# - Reduce the risk of overfitting.\n",
    "# - Handle variance and bias better compared to individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. What is bagging?\n",
    "# A3: \n",
    "# Bagging, or Bootstrap Aggregating, is an ensemble technique that involves training multiple models on \n",
    "# different subsets of data (obtained through resampling with replacement) and aggregating their \n",
    "# predictions (e.g., majority voting for classification or averaging for regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. What is boosting?\n",
    "# A4: \n",
    "# Boosting is an ensemble technique that combines weak learners sequentially. Each subsequent model \n",
    "# focuses on correcting the errors of the previous ones. Examples include AdaBoost and Gradient Boosting.\n",
    "\n",
    "# Q5. What are the benefits of using ensemble techniques?\n",
    "# A5: \n",
    "# Benefits include:\n",
    "# - Increased accuracy and stability.\n",
    "# - Reduced risk of overfitting (in techniques like bagging).\n",
    "# - Ability to leverage multiple models to handle different aspects of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. Are ensemble techniques always better than individual models?\n",
    "# A6: \n",
    "# Not always. While ensemble techniques generally improve performance, they can:\n",
    "# - Be computationally expensive.\n",
    "# - Overfit if not carefully implemented.\n",
    "# - Provide diminishing returns in cases where individual models are already highly optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. How is the confidence interval calculated using bootstrap?\n",
    "# A7: \n",
    "# To calculate the confidence interval using bootstrap:\n",
    "# 1. Resample the dataset with replacement to create multiple bootstrap samples.\n",
    "# 2. Compute the statistic of interest (e.g., mean) for each bootstrap sample.\n",
    "# 3. Determine the percentile values (e.g., 2.5th and 97.5th percentiles for a 95% confidence interval) \n",
    "#    from the distribution of the computed statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8. How does bootstrap work and What are the steps involved in bootstrap?\n",
    "# A8: \n",
    "# Bootstrap involves the following steps:\n",
    "# 1. Resample the original dataset with replacement to create multiple bootstrap samples of the same \n",
    "#    size as the original dataset.\n",
    "# 2. Compute the desired statistic (e.g., mean, median) for each bootstrap sample.\n",
    "# 3. Use the distribution of computed statistics to estimate confidence intervals or assess variability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: [14.03, 15.09]\n"
     ]
    }
   ],
   "source": [
    "# Q9. A researcher wants to estimate the mean height of a population of trees. They measure the height of a\n",
    "# sample of 50 trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use\n",
    "# bootstrap to estimate the 95% confidence interval for the population mean height.\n",
    "\n",
    "# A9:\n",
    "import numpy as np\n",
    "\n",
    "# Given data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "sample_mean = 15\n",
    "sample_std = 2\n",
    "sample_size = 50\n",
    "num_bootstrap_samples = 1000\n",
    "\n",
    "# Generate bootstrap samples\n",
    "original_sample = np.random.normal(loc=sample_mean, scale=sample_std, size=sample_size)\n",
    "bootstrap_means = []\n",
    "for _ in range(num_bootstrap_samples):\n",
    "    bootstrap_sample = np.random.choice(original_sample, size=sample_size, replace=True)\n",
    "    bootstrap_means.append(np.mean(bootstrap_sample))\n",
    "\n",
    "# Calculate 95% confidence interval\n",
    "ci_lower = np.percentile(bootstrap_means, 2.5)\n",
    "ci_upper = np.percentile(bootstrap_means, 97.5)\n",
    "\n",
    "print(f\"95% Confidence Interval: [{ci_lower:.2f}, {ci_upper:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
